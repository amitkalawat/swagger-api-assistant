{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8229ce46-b184-4eae-a10f-4a2489250929",
   "metadata": {},
   "source": [
    "## Fine-tune Embedding Models\n",
    "\n",
    "Fine-tuning the embedding model is a critical step in enhancing the performance of RAG systems. These systems rely on retrieving relevant information from a corpus to augment the language model's generation capabilities. However, pre-trained embedding models are often trained on general-purpose datasets, which may not accurately capture the nuances and semantics specific to a particular domain or use case. Fine-tuning the embedding model on domain-specific data allows the RAG system to adapt to the target domain, improving the relevance and accuracy of retrieved information. \n",
    "\n",
    "The notebooks prepares the dataset for the lab by generating sythetic questions related to Amazon and Google's 10k documents. **A copy of the output dataset is already available in the `data` directory, so you don't have to run the notebook to start on the lab.** But if you are interested to see how the data are prepared, please execute each cell below sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2cbc00-7370-4826-ba4b-5041d07913eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -Uq PyPDF2==3.0.1\n",
    "!pip install -Uq langchain==0.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde059f3-d001-4278-a745-677ce7d5f85a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "from PyPDF2 import PdfReader \n",
    "import uuid\n",
    "import json\n",
    "import re\n",
    "\n",
    "train_file = \"google_10k.pdf\"\n",
    "val_file = \"amazon_10k.pdf\"\n",
    "\n",
    "train_corpus_location = './data/train_corpus.json'\n",
    "val_corpus_location = './data/val_corpus.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e64ee-ca5a-40b1-9fa8-0b74f6990482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pdf_to_chunks(pdf_file, chunk_size=5000):\n",
    "\n",
    "    # Load PDF\n",
    "    pdf = PdfReader(pdf_file)\n",
    "\n",
    "    # Extract text\n",
    "    text = \"\"\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    # Strip special characters\n",
    "    text = re.sub(r'[\\W_]+', ' ', text)\n",
    "\n",
    "    # Initialize chunks dict\n",
    "    chunks = {}\n",
    "\n",
    "    # Split text into chunks\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        chunk = text[i:i+chunk_size]\n",
    "        chunk_id = str(uuid.uuid4())\n",
    "        chunks[chunk_id] = chunk\n",
    "        \n",
    "    # Return JSON object\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a3b80-53ea-490c-82af-d0fa36adf0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_corpus = pdf_to_chunks(train_file, chunk_size=750)\n",
    "val_corpus = pdf_to_chunks(val_file, chunk_size=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d980101-8b85-4e66-aadd-3fe449c1a106",
   "metadata": {},
   "source": [
    "Save the our corpus in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482b007-5a80-45fe-ba01-037255d76715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(train_corpus_location, 'w+') as f:\n",
    "    json.dump(train_corpus, f)\n",
    "\n",
    "with open(val_corpus_location, 'w+') as f:\n",
    "    json.dump(val_corpus, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6818bc3a-9ee2-4a76-935c-f4da86e92549",
   "metadata": {},
   "source": [
    "### Generate synthetic queries\n",
    "\n",
    "Now, we use Claude v2 from Amazon Bedrock to generate questions using each text chunk in the corpus as context.\n",
    "\n",
    "Each pair of (generated question, text chunk used as context) becomes a datapoint in the finetuning dataset (either for training or evaluation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607a079-52cc-40ca-a6dd-299cd9579712",
   "metadata": {},
   "source": [
    "### > initialize boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b67ca0-962b-467e-8c3a-a60973625d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "from langchain.llms import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "boto_config = Config(\n",
    "        connect_timeout=1, read_timeout=300,\n",
    "        retries={'max_attempts': 1})\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "\n",
    "bedrock_runtime = boto_session.client(\n",
    "    service_name = \"bedrock-runtime\", config=boto_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f32ac-6d26-4dec-9594-f2cd39eecd8e",
   "metadata": {},
   "source": [
    "### > initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f0ac2-5725-4e71-a1c4-bd3ab02eb8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize the LLM model\n",
    "model_id = 'anthropic.claude-v2:1'\n",
    "\n",
    "#Pricing of LLM model\n",
    "claudev2_input=0.008/1000\n",
    "claudev2_output=0.024/1000\n",
    "\n",
    "inference_modifier = {'max_tokens_to_sample':4096, \n",
    "                  \"temperature\":0,\n",
    "                  \"top_k\":250,\n",
    "                  \"top_p\":1,\n",
    "                  \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d5839-ec8d-4cd5-8cfa-e3eb17681467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"number_of_qs\"], \n",
    "    template=\"\"\"\n",
    "    Human: You are a teacher. your task is to setup questions for an upcoming exam. The questions should be diverse in nature across the document. Only generate the questions within the <context> provided.\n",
    "    \n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \n",
    "    Now generate {number_of_qs} questions in <questions>. No explanation, no bullet list, one carriage return between questions, just the questions only.\n",
    "    \n",
    "    Assistant:<questions>\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b768f-201e-4581-9518-427ca03f1b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_queries(corpus, prompt_template, number_of_qs=2):\n",
    "    model = Bedrock(model_id=model_id, \n",
    "          client=bedrock_runtime, \n",
    "          model_kwargs=inference_modifier)\n",
    "\n",
    "    queries = {}\n",
    "    relevant_docs = {}\n",
    "    for node_id, chunk in tqdm(corpus.items()):\n",
    "        prompt = prompt_template.format(context=chunk, number_of_qs=number_of_qs)\n",
    "        response = model.invoke(prompt)\n",
    "        result = str(response).strip().replace(\"\\n</questions>\", \"\").split(\"\\n\")\n",
    "        questions = [\n",
    "            re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip() for question in result\n",
    "        ]\n",
    "        questions = [question for question in questions if len(question) > 0]\n",
    "\n",
    "        for q in questions:\n",
    "            q_id = str(uuid.uuid4())\n",
    "            queries[q_id] = q\n",
    "            relevant_docs[q_id] = [node_id]\n",
    "    return queries, relevant_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093664de-473f-4ade-820a-adb5785f4087",
   "metadata": {},
   "source": [
    "### > Test corps\n",
    "test_corps = {'a302c0e5-44c7-4518-9022-7f5adcf357fa': 'UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington D C 20549 FORM 10 K Mark One ANNUAL REPORT PURSUANT TO SECTION 13 OR 15 d OF THE SECURITIES EXCHANGE ACT OF 1934 For the fiscal year ended December 31 2022 OR TRANSITION REPORT PURSUANT TO SECTION 13 OR 15 d OF THE SECURITIES EXCHANGE ACT OF 1934 For the transition period from to Commission file number 001 37580 Alphabet Inc Exact name of registrant as specified in its charter Delaware 61 1767919 State or other jurisdiction of incorporation or organization I R S Employer Identification No 1600 Amphitheatre Parkway Mountain View CA 94043 Address of principal executive offices including zip code 650 253 0000 Registrant s telephone number including area code Securities registered purs',\n",
    " 'ebc9dab5-73db-4da3-a8da-674ecb128187': 'uant to Section 12 b of the Act Title of each class Trading Symbol s Name of each exchange on which registered Class A Common Stock 0 001 par value GOOGL Nasdaq Stock Market LLC Nasdaq Global Select Market Class C Capital Stock 0 001 par value GOOG Nasdaq Stock Market LLC Nasdaq Global Select Market Securities registered pursuant to Section 12 g of the Act Title of each class None Indicate by check mark if the registrant is a well known seasoned issuer as defined in Rule 405 of the Securities Act Yes No Indicate by check mark if the registrant is not required to file reports pursuant to Section 13 or Section 15 d of the Act Yes No Indicate by check mark whether the registrant 1 has filed all reports required to be filed by Section 13 or 15 ',    \n",
    "}\n",
    "test_corps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b3394-37e0-4c83-a8f7-f0b7e50d4e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_queries, train_relevant_docs = generate_queries(train_corpus, prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf57e4-84af-4697-95ca-487b57dc21fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_queries, val_relevant_docs = generate_queries(val_corpus, prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909c9ee-a4c5-4e2a-ac39-4e5b54992e0d",
   "metadata": {},
   "source": [
    "### > create the final training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285d290-72f6-4aad-af46-d63eccdbd722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = './data/train_dataset.json'\n",
    "val_data_path = './data/val_dataset.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bcfe58-8568-4af2-92c3-0fd656513979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = {\n",
    "    'queries': train_queries,\n",
    "    'corpus': train_corpus,\n",
    "    'relevant_docs': train_relevant_docs,\n",
    "}\n",
    "\n",
    "val_dataset = {\n",
    "    'queries': val_queries,\n",
    "    'corpus': val_corpus,\n",
    "    'relevant_docs': val_relevant_docs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73776523-ad7a-46f2-aa6c-202822b6eec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(train_data_path, 'w+') as f:\n",
    "    json.dump(train_dataset, f)\n",
    "\n",
    "with open(val_data_path, 'w+') as f:\n",
    "    json.dump(val_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cae87c-ebe6-4f15-a426-e2d46abe58ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
