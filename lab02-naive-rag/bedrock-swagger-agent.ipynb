{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1622b30c-ff9a-4768-8249-0a0c8dbcab37",
   "metadata": {},
   "source": [
    "## Naive RAG Lab\n",
    "\n",
    "In this lab, we will build an naive RAG solution leveraging pre-trained foundation models and the knowledge base feature from Amazon Bedrock. Doing so, you will learn various components that makes up a RAG system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7470e9-53f6-4714-81b0-50b9cbfdbf26",
   "metadata": {},
   "source": [
    "## Pre-req\n",
    "You must run the notebook in [lab01](../lab01-managed-rag/) to load the necessary data to S3, and stor the parameters for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a89d74e-6e82-4f99-bcf3-1bbe58aca686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_875/2588010541.py:2: UserWarning: Warning: if you did not run lab01, please go back and run the lab01 notebook!\n",
      "  warnings.warn(\"Warning: if you did not run lab01, please go back and run the lab01 notebook!\")\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.warn(\"Warning: if you did not run lab01, please go back and run the lab01 notebook!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b259d2bc-c6c9-4df7-b6b7-e17b9d4b4918",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9d7eaec-4f0b-485d-828f-71364721041e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opensearch-py==2.3.1\n",
      "  Downloading opensearch_py-2.3.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from opensearch-py==2.3.1) (1.26.18)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from opensearch-py==2.3.1) (2.31.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from opensearch-py==2.3.1) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from opensearch-py==2.3.1) (2.9.0)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /opt/conda/lib/python3.10/site-packages (from opensearch-py==2.3.1) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py==2.3.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py==2.3.1) (3.7)\n",
      "Downloading opensearch_py-2.3.1-py2.py3-none-any.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.3/327.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opensearch-py\n",
      "Successfully installed opensearch-py-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting retrying==1.3.4\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: six>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from retrying==1.3.4) (1.16.0)\n",
      "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: retrying\n",
      "  Attempting uninstall: retrying\n",
      "    Found existing installation: retrying 1.3.3\n",
      "    Uninstalling retrying-1.3.3:\n",
      "      Successfully uninstalled retrying-1.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dash 2.17.0 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.17.0 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.17.0 requires dash-table==5.0.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed retrying-1.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U opensearch-py==2.3.1\n",
    "%pip install -U retrying==1.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7380e0b2-0589-4205-9758-6da9a67a1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import random\n",
    "import pprint as pp\n",
    "import uuid\n",
    "import json\n",
    "from retrying import retry\n",
    "from utility import create_bedrock_execution_role, create_oss_policy_attach_bedrock_execution_role, create_policies_in_oss\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "# auth for opensearch\n",
    "boto3_session = boto3.Session()\n",
    "region_name = boto3_session.region_name\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "credentials = boto3_session.get_credentials()\n",
    "\n",
    "# opensearch service\n",
    "service = 'aoss'\n",
    "awsauth = auth = AWSV4SignerAuth(credentials, region_name, service)\n",
    "\n",
    "\n",
    "bedrock_agent_client = boto3_session.client('bedrock-agent', region_name=region_name)\n",
    "\n",
    "# bucket and parameter stored from lab01\n",
    "%store -r bucket\n",
    "%store -r prefix\n",
    "%store -r data_dir\n",
    "%store -r yml_dir\n",
    "%store -r uml_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db990f08-015e-465b-9267-69d9738f4d10",
   "metadata": {},
   "source": [
    "## Create a vector store - OpenSearch Serverless index\n",
    "\n",
    "### Step 1 - Create OSS policies and collection\n",
    "Firt of all we have to create a vector store. In this section we will use *Amazon OpenSerach serverless.*\n",
    "\n",
    "Amazon OpenSearch Serverless is a serverless option in Amazon OpenSearch Service. As a developer, you can use OpenSearch Serverless to run petabyte-scale workloads without configuring, managing, and scaling OpenSearch clusters. You get the same interactive millisecond response times as OpenSearch Service with the simplicity of a serverless environment. Pay only for what you use by automatically scaling resources to provide the right amount of capacity for your application—without impacting data ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d693b588-e7cd-4ba3-9ce1-fb5d7599fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = random.randrange(200, 900)\n",
    "vector_store_name = f'swagger-api-{suffix}'\n",
    "index_name = f\"swagger-api-{suffix}\"\n",
    "aoss_client = boto3_session.client('opensearchserverless')\n",
    "bedrock_kb_execution_role = create_bedrock_execution_role(bucket_name=bucket)\n",
    "bedrock_kb_execution_role_arn = bedrock_kb_execution_role['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "574555e4-786a-4179-a7d6-17c1f31a3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create security, network and data access policies within OSS\n",
    "encryption_policy, network_policy, access_policy = create_policies_in_oss(vector_store_name=vector_store_name,\n",
    "                       aoss_client=aoss_client,\n",
    "                       bedrock_kb_execution_role_arn=bedrock_kb_execution_role_arn)\n",
    "collection = aoss_client.create_collection(name=vector_store_name,type='VECTORSEARCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce39bac5-253f-4a38-b3f8-8f2daf513133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
      "                                      'content-length': '307',\n",
      "                                      'content-type': 'application/x-amz-json-1.0',\n",
      "                                      'date': 'Sat, 01 Jun 2024 04:04:52 GMT',\n",
      "                                      'x-amzn-requestid': 'd5c1c7e3-a23e-4657-ada8-68c0dd2cee31'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'd5c1c7e3-a23e-4657-ada8-68c0dd2cee31',\n",
      "                      'RetryAttempts': 0},\n",
      " 'createCollectionDetail': {'arn': 'arn:aws:aoss:us-west-2:974171775829:collection/ruq5qwuvpwnqdehuz76d',\n",
      "                            'createdDate': 1717214692104,\n",
      "                            'id': 'ruq5qwuvpwnqdehuz76d',\n",
      "                            'kmsKeyArn': 'auto',\n",
      "                            'lastModifiedDate': 1717214692104,\n",
      "                            'name': 'swagger-api-828',\n",
      "                            'standbyReplicas': 'ENABLED',\n",
      "                            'status': 'CREATING',\n",
      "                            'type': 'VECTORSEARCH'}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(collection)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50fe47de-4852-482d-97da-110265e90671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ruq5qwuvpwnqdehuz76d.us-west-2.aoss.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "collection_id = collection['createCollectionDetail']['id']\n",
    "host = collection_id + '.' + region_name + '.aoss.amazonaws.com'\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "176be68c-c749-4df1-a998-663889acabfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opensearch serverless arn:  arn:aws:iam::974171775829:policy/AmazonBedrockOSSPolicyForKnowledgeBase_209\n"
     ]
    }
   ],
   "source": [
    "# create oss policy and attach it to Bedrock execution role\n",
    "create_oss_policy_attach_bedrock_execution_role(collection_id=collection_id,\n",
    "                                                bedrock_kb_execution_role=bedrock_kb_execution_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f35d671-1aa4-415b-87f0-6beb336fcfc0",
   "metadata": {},
   "source": [
    "### Step 2 - Create vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7625ad3f-9822-4ca7-9fec-3aa93c7f305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = f\"bedrock-sample-index-{suffix}\"\n",
    "body_json = {\n",
    "   \"settings\": {\n",
    "      \"index.knn\": \"true\"\n",
    "   },\n",
    "   \"mappings\": {\n",
    "      \"properties\": {\n",
    "         \"vector\": {\n",
    "            \"type\": \"knn_vector\",\n",
    "            \"dimension\": 1536,\n",
    "            \"method\": {\n",
    "                \"name\": \"hnsw\",\n",
    "                \"space_type\": \"innerproduct\",\n",
    "                \"engine\": \"faiss\",\n",
    "                \"parameters\": {\n",
    "                  \"ef_construction\": 256,\n",
    "                  \"m\": 48\n",
    "                }\n",
    "             }\n",
    "         },\n",
    "         \"text\": {\n",
    "            \"type\": \"text\"\n",
    "         },\n",
    "         \"text-metadata\": {\n",
    "            \"type\": \"text\"         \n",
    "         }\n",
    "      }\n",
    "   }\n",
    "}\n",
    "# Build the OpenSearch client\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")\n",
    "# # It can take up to a minute for data access rules to be enforced\n",
    "time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f23e0b4a-1189-477a-84ab-de83741169ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating index:\n",
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'bedrock-sample-index-828'}\n"
     ]
    }
   ],
   "source": [
    "# Create index\n",
    "response = oss_client.indices.create(index=index_name, body=json.dumps(body_json))\n",
    "print('\\nCreating index:')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde8bac3-2f34-4260-a26e-2c0efbb94da4",
   "metadata": {},
   "source": [
    "## Create Knowledge Base\n",
    "Steps:\n",
    "- initialize Open search serverless configuration which will include collection ARN, index name, vector field, text field and metadata field.\n",
    "- initialize chunking strategy, based on which KB will split the documents into pieces of size equal to the chunk size mentioned in the `chunkingStrategyConfiguration`.\n",
    "- initialize the s3 configuration, which will be used to create the data source object later.\n",
    "- initialize the Titan embeddings model ARN, as this will be used to create the embeddings for each of the text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6c0b3cf-77f6-4a1b-97cd-a576575beb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearchServerlessConfiguration = {\n",
    "            \"collectionArn\": collection[\"createCollectionDetail\"]['arn'],\n",
    "            \"vectorIndexName\": index_name,\n",
    "            \"fieldMapping\": {\n",
    "                \"vectorField\": \"vector\",\n",
    "                \"textField\": \"text\",\n",
    "                \"metadataField\": \"text-metadata\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "chunkingStrategyConfiguration = {\n",
    "    \"chunkingStrategy\": \"NONE\",\n",
    "}\n",
    "\n",
    "s3Configuration = {\n",
    "    \"bucketArn\": f\"arn:aws:s3:::{bucket}\",\n",
    "    \"inclusionPrefixes\":[f\"{prefix}/yml_questions/\"] # you can use this if you want to create a KB using data within s3 prefixes.\n",
    "}\n",
    "\n",
    "embeddingModelArn = f\"arn:aws:bedrock:{region_name}::foundation-model/amazon.titan-embed-text-v1\"\n",
    "\n",
    "kb_name = f\"bedrock-sample-knowledge-base-{suffix}\"\n",
    "description = \"Swagger OpenAPI knowledge base.\"\n",
    "roleArn = bedrock_kb_execution_role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c12d9fc-a1e9-4607-9d7c-dbcd9b6b7f12",
   "metadata": {},
   "source": [
    "Provide the above configurations as input to the `create_knowledge_base` method, which will create the Knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3f1013c-a0de-4c69-8308-9de70c20f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KnowledgeBase\n",
    "from retrying import retry\n",
    "\n",
    "@retry(wait_random_min=1000, wait_random_max=2000,stop_max_attempt_number=7)\n",
    "def create_knowledge_base_func():\n",
    "    create_kb_response = bedrock_agent_client.create_knowledge_base(\n",
    "        name = kb_name,\n",
    "        description = description,\n",
    "        roleArn = roleArn,\n",
    "        knowledgeBaseConfiguration = {\n",
    "            \"type\": \"VECTOR\",\n",
    "            \"vectorKnowledgeBaseConfiguration\": {\n",
    "                \"embeddingModelArn\": embeddingModelArn\n",
    "            }\n",
    "        },\n",
    "        storageConfiguration = {\n",
    "            \"type\": \"OPENSEARCH_SERVERLESS\",\n",
    "            \"opensearchServerlessConfiguration\":opensearchServerlessConfiguration\n",
    "        }\n",
    "    )\n",
    "    return create_kb_response[\"knowledgeBase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537d81d1-b296-4a7a-bef3-22a7452b54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    kb = create_knowledge_base_func()\n",
    "except Exception as err:\n",
    "    print(f\"{err=}, {type(err)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b97f45-49e0-440e-be3c-10b4d1fe7757",
   "metadata": {},
   "source": [
    "Next we need to create a data source, which will be associated with the knowledge base created above. Once the data source is ready, we can then start to ingest the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa977390-1cbb-4b82-8626-7f0300033ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get KnowledgeBase \n",
    "get_kb_response = bedrock_agent_client.get_knowledge_base(knowledgeBaseId = kb['knowledgeBaseId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c84b2d1b-6708-4dd0-a828-82d4ee5acf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'createdAt': datetime.datetime(2024, 6, 1, 4, 13, 2, 187233, tzinfo=tzlocal()),\n",
      " 'dataSourceConfiguration': {'s3Configuration': {'bucketArn': 'arn:aws:s3:::sagemaker-us-west-2-974171775829',\n",
      "                                                 'inclusionPrefixes': ['swagger_codegen/yml_questions/']},\n",
      "                             'type': 'S3'},\n",
      " 'dataSourceId': '532DYM9UHD',\n",
      " 'description': 'Swagger OpenAPI knowledge base.',\n",
      " 'knowledgeBaseId': 'TN24JCHRAN',\n",
      " 'name': 'bedrock-sample-knowledge-base-828',\n",
      " 'status': 'AVAILABLE',\n",
      " 'updatedAt': datetime.datetime(2024, 6, 1, 4, 13, 2, 187233, tzinfo=tzlocal()),\n",
      " 'vectorIngestionConfiguration': {'chunkingConfiguration': {'chunkingStrategy': 'NONE'}}}\n"
     ]
    }
   ],
   "source": [
    "# Create a DataSource in KnowledgeBase \n",
    "create_ds_response = bedrock_agent_client.create_data_source(\n",
    "    name = kb_name,\n",
    "    description = description,\n",
    "    knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "    dataSourceConfiguration = {\n",
    "        \"type\": \"S3\",\n",
    "        \"s3Configuration\":s3Configuration\n",
    "    },\n",
    "    vectorIngestionConfiguration = {\n",
    "        \"chunkingConfiguration\": chunkingStrategyConfiguration\n",
    "    }\n",
    ")\n",
    "ds = create_ds_response[\"dataSource\"]\n",
    "# # It can take up to a minute for data access rules to be enforced\n",
    "time.sleep(20)\n",
    "pp.pprint(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a1a07-68bd-4472-aa0f-e3ecc541aa75",
   "metadata": {},
   "source": [
    "### Start ingestion job\n",
    "Once the KB and data source is created, we can start the ingestion job.\n",
    "During the ingestion job, KB will fetch the documents in the data source, pre-process it to extract text, chunk it based on the chunking size provided, create embeddings of each chunk and then write it to the vector database, in this case OSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d89ee2c-4757-4ab0-a4fe-df4cb810cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start an ingestion job\n",
    "start_job_response = bedrock_agent_client.start_ingestion_job(knowledgeBaseId = kb['knowledgeBaseId'], dataSourceId = ds[\"dataSourceId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4d27676-0634-4005-bdc7-95b79e7f36fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataSourceId': '532DYM9UHD',\n",
      " 'ingestionJobId': 'HBSZLQINWL',\n",
      " 'knowledgeBaseId': 'TN24JCHRAN',\n",
      " 'startedAt': datetime.datetime(2024, 6, 1, 4, 13, 22, 754503, tzinfo=tzlocal()),\n",
      " 'statistics': {'numberOfDocumentsDeleted': 0,\n",
      "                'numberOfDocumentsFailed': 0,\n",
      "                'numberOfDocumentsScanned': 0,\n",
      "                'numberOfModifiedDocumentsIndexed': 0,\n",
      "                'numberOfNewDocumentsIndexed': 0},\n",
      " 'status': 'STARTING',\n",
      " 'updatedAt': datetime.datetime(2024, 6, 1, 4, 13, 22, 754503, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "job = start_job_response[\"ingestionJob\"]\n",
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b235dae5-99be-4af2-8c33-db4c6c101830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataSourceId': '532DYM9UHD',\n",
      " 'ingestionJobId': 'HBSZLQINWL',\n",
      " 'knowledgeBaseId': 'TN24JCHRAN',\n",
      " 'startedAt': datetime.datetime(2024, 6, 1, 4, 13, 22, 754503, tzinfo=tzlocal()),\n",
      " 'statistics': {'numberOfDocumentsDeleted': 0,\n",
      "                'numberOfDocumentsFailed': 0,\n",
      "                'numberOfDocumentsScanned': 5,\n",
      "                'numberOfModifiedDocumentsIndexed': 0,\n",
      "                'numberOfNewDocumentsIndexed': 5},\n",
      " 'status': 'COMPLETE',\n",
      " 'updatedAt': datetime.datetime(2024, 6, 1, 4, 13, 33, 344865, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "# Get job \n",
    "while(job['status']!='COMPLETE' ):\n",
    "  get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "      knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "        dataSourceId = ds[\"dataSourceId\"],\n",
    "        ingestionJobId = job[\"ingestionJobId\"]\n",
    "  )\n",
    "  job = get_job_response[\"ingestionJob\"]\n",
    "pp.pprint(job)\n",
    "time.sleep(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "522280f4-7246-4295-a9cf-361bc9f8a79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'kb_id' (str)\n",
      "'TN24JCHRAN'\n"
     ]
    }
   ],
   "source": [
    "kb_id = kb[\"knowledgeBaseId\"]\n",
    "%store kb_id\n",
    "pp.pprint(kb_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0c915-9eae-41f8-8f55-0a08ee148496",
   "metadata": {},
   "source": [
    "## Test the knowledge base\n",
    "### Using RetrieveAndGenerate API\n",
    "Behind the scenes, RetrieveAndGenerate API converts queries into embeddings, searches the knowledge base, and then augments the foundation model prompt with the search results as context information and returns the FM-generated response to the question. For multi-turn conversations, Knowledge Bases manage short-term memory of the conversation to provide more contextual results.\n",
    "\n",
    "The output of the RetrieveAndGenerate API includes the generated response, source attribution as well as the retrieved text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9da746fb-6bd8-470e-aaae-d7be31ce2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out KB using RetrieveAndGenerate API\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region_name)\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\" # try with both claude instant as well as claude-v2. for claude v2 - \"anthropic.claude-v2\"\n",
    "model_arn = f'arn:aws:bedrock:{region_name}::foundation-model/{model_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5fa3c4d-6429-47c9-be7b-f461fae74b91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To add a new pet using the petstore API, you need to send a POST request to the /pets endpoint with a request body containing a NewPet object. The NewPet object must include the name property, and can optionally include the tag property.\n",
       "\n",
       "Here's an example Python code to add a new pet using the requests library: import requests\n",
       "\n",
       "url = \"https://petstore.example.com/pets\"\n",
       "\n",
       "payload = {\n",
       "    \"name\": \"Buddy\",\n",
       "    \"tag\": \"dog\"\n",
       "}\n",
       "\n",
       "headers = {\n",
       "    \"Content-Type\": \"application/json\"\n",
       "}\n",
       "\n",
       "response = requests.post(url, json=payload, headers=headers)\n",
       "\n",
       "if response.status_code == 200:\n",
       "    print(\"Pet created successfully!\")\n",
       "    print(response.json())\n",
       "else:\n",
       "    print(f\"Error creating pet: {response.status_code} - {response.text}\")"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "query = \"How do I add a new pet using the petstore api? Can you generate a test code in python?\"\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        'text': query\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        'type': 'KNOWLEDGE_BASE',\n",
    "        'knowledgeBaseConfiguration': {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            'modelArn': model_arn\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "generated_text = response['output']['text']\n",
    "\n",
    "display(Markdown(generated_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec9b91-5bc9-400c-9e2a-a5cd7ed6ef89",
   "metadata": {},
   "source": [
    "## > Create a Simple Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f412fd1-edcf-4a91-904b-2ffa77018950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as ipw\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class ChatUX:\n",
    "    \"\"\" A chat UX using IPWidgets\n",
    "    \"\"\"\n",
    "    def __init__(self, qa):\n",
    "        self.qa = qa\n",
    "        self.name = None\n",
    "        self.b=None\n",
    "        self.out = ipw.Output()\n",
    "        self.session_id = None\n",
    "\n",
    "    def start_chat(self):\n",
    "        print(\"Let's chat!\")\n",
    "        display(self.out)\n",
    "        self.chat(None)\n",
    "\n",
    "    def chat(self, _):\n",
    "        if self.name is None:\n",
    "            prompt = \"\"\n",
    "        else:\n",
    "            prompt = self.name.value\n",
    "        if 'q' == prompt or 'quit' == prompt or 'Q' == prompt:\n",
    "            print(\"Thank you , that was a nice chat !!\")\n",
    "            return\n",
    "        elif len(prompt) > 0:\n",
    "            with self.out:\n",
    "                thinking = ipw.Label(value=f\"Thinking...\")\n",
    "                display(thinking)\n",
    "                try:\n",
    "                    if self.session_id:\n",
    "                        response = self.qa.retrieve_and_generate(\n",
    "                            sessionId=self.session_id,\n",
    "                            input={\n",
    "                                'text': prompt\n",
    "                            },\n",
    "                            retrieveAndGenerateConfiguration={\n",
    "                                'type': 'KNOWLEDGE_BASE',\n",
    "                                'knowledgeBaseConfiguration': {\n",
    "                                    'knowledgeBaseId': kb_id,\n",
    "                                    'modelArn': model_arn\n",
    "                                }\n",
    "                            }\n",
    "                        )\n",
    "                    else:\n",
    "                        response = self.qa.retrieve_and_generate(\n",
    "                            input={\n",
    "                                'text': prompt\n",
    "                            },\n",
    "                            retrieveAndGenerateConfiguration={\n",
    "                                'type': 'KNOWLEDGE_BASE',\n",
    "                                'knowledgeBaseConfiguration': {\n",
    "                                    'knowledgeBaseId': kb_id,\n",
    "                                    'modelArn': model_arn\n",
    "                                }\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                    self.session_id = response['sessionId']\n",
    "                    result = response['output']['text']\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    result = \"No answer\"\n",
    "                thinking.value=\"\"\n",
    "                print(f\"AI: {result}\")\n",
    "                self.name.disabled = True\n",
    "                self.b.disabled = True\n",
    "                self.name = None\n",
    "\n",
    "        if self.name is None:\n",
    "            with self.out:\n",
    "                self.name = ipw.Text(description=\"You: \", placeholder='q to quit')\n",
    "                self.b = ipw.Button(description=\"Send\")\n",
    "                self.b.on_click(self.chat)\n",
    "                display(ipw.Box(children=(self.name, self.b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac85427-eef2-488b-8fff-423c2c32ec07",
   "metadata": {},
   "source": [
    "### > Sample Questions\n",
    "How many routes in flowerstore?\n",
    "How do I create a new pet in petstore?\n",
    "What is the response code if a pet is not available?\n",
    "How do I delete a book from bookstore?\n",
    "Can you generate a sample code in python to create an new author in bookstore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb9de5c6-505c-45de-8c44-0fdc71a4605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8861748857457e82b7889cc88aab1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = ChatUX(bedrock_agent_runtime_client)\n",
    "chat.start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6d3191-558a-4a55-b78d-5a0e026a6fcc",
   "metadata": {},
   "source": [
    "### > Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309589f-9d32-48b5-a5cf-d8d005299485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
